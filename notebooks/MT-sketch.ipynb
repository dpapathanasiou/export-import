{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "A sketch of the [machine translation tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) from the [PyTorch Tutorials](https://pytorch.org/tutorials/index.html).\n",
    "\n",
    "It's the closest analogy to automated document conversion, so this is an attempt to study its internals.\n",
    "\n",
    "## Model\n",
    "\n",
    "This is a sequence-to-sequence (seq2seq) model, consisting of a pair of [recurrent neural networks (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network), the encoder and decoder. \n",
    "\n",
    "The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.\n",
    "\n",
    "![diagram](images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "This is the first half of the RNN seq2seq network, aka [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf).\n",
    "\n",
    "For every input (word token, in this example) the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
    "\n",
    "![encoder](images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # using a multi-layer gated recurrent unit (GRU) \n",
    "        # as an improvement over long short-term memory (LSTM) \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input_layer, hidden_layer):\n",
    "        embedded = self.embedding(input_layer).view(1, 1, -1)\n",
    "        output_layer, hidden_layer = self.gru(embedded, hidden_layer)\n",
    "        return output_layer, hidden_layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "The is the second half of the model, another RNN that takes the encoder's output vectors as its input, and outputs a sequence of words to create the translation:\n",
    "\n",
    "![decoder](images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_layer, hidden_layer):\n",
    "        output_layer = F.relu(self.embedding(input).view(1, 1, -1))\n",
    "        output_layer, hidden_layer = self.gru(output_layer, hidden_layer)\n",
    "        output_layer = self.softmax(self.out(output_layer[0]))\n",
    "        return output_layer, hidden_layer\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder\n",
    "\n",
    "Without this, the context vector which is passed betweeen the encoder and decoder carries the burden of encoding the entire sentence.\n",
    "\n",
    "The attention RNN allows the decoder network to \"focus\" on a different part of the encoder's outputs for every step of the decoder's own outputs.\n",
    "\n",
    "![diagram](images/attention-decoder.png)\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward layer, `attn`, using the decoder's input and hidden state as inputs.\n",
    "\n",
    "Rather than using [bucketing](https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing) for handling inputs of variable length in the training data, this example chooses a maximum sentence length that gets applied to all inputs: sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
    "\n",
    "![diagram](images/attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout, max_length):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "        sef.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attention = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attention_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input_layer, hidden_layer, encoder_output):\n",
    "        embedded = self.dropout(self.embedding(input_layer).view(1, 1, -1))\n",
    "        attention_weights = F.softmax(self.attention(torch.cat((embedded[0], hidden_layer[0]), 1)), dim=1)\n",
    "        attention_applied = torch.bmm(attention_weights.unsqueeze(0), encoder_output.unsqueeze(0))\n",
    "        output_layer = self.attention_combine(torch.cat((embedded[0], attention_applied[0]), 1)).unsqueeze(0)\n",
    "        output_layer, hidden_layer = self.gru(F.relu(output_layer), hidden_layer)\n",
    "        output_layer = F.log_softmax(self.out(output_layer[0]), dim=1)\n",
    "        return output_layer, hidden_layer, attention_weights\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Using the tab-delimited examples from [Anki](https://www.manythings.org/anki/) to see if it's possible to produce a simple English to Japanese translation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: parsing Japanese text in python\n",
    "\n",
    "This proved to be surprisingly complicated. \n",
    "\n",
    "[KyTea](http://www.phontron.com/kytea/) would not install until going down to version `0.3.2`, and even then would not run properly.\n",
    "\n",
    "[This guide](images/japanese-spacy-and-mecab.pdf) (archived from the [original](https://www.dampfkraft.com/nlp/japanese-spacy-and-mecab.html)) was helpful, but I needed a few more tweaks to make it work:\n",
    "\n",
    "* `sudo ldconfig` gets around the `error while loading shared libraries: libmecab.so.2` building `unidic-mecab-2.1.2_src` (hat tip to [tatsuyaoiw](http://tatsuyaoiw.hatenablog.com/entry/20120414/1334397985))\n",
    "* edited `/usr/local/etc/mecabrc` so that `dicdir` is defined as `dicdir = /usr/local/lib/mecab/dic/unidic`\n",
    "* after `pip install mecab-python3==0.7` and `pip install spacy` I also needed `pip install fugashi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-12 19:27:55--  https://www.manythings.org/anki/jpn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:3037::6818:6cc4, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2127866 (2.0M) [application/zip]\n",
      "Saving to: ‘/tmp/jpn-eng.zip’\n",
      "\n",
      "jpn-eng.zip         100%[===================>]   2.03M   633KB/s    in 3.3s    \n",
      "\n",
      "2020-05-12 19:27:58 (633 KB/s) - ‘/tmp/jpn-eng.zip’ saved [2127866/2127866]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P /tmp https://www.manythings.org/anki/jpn-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/jpn-eng.zip\n",
      "  inflating: /tmp/jpn.txt            \n",
      "  inflating: /tmp/_about.txt         \n"
     ]
    }
   ],
   "source": [
    "!unzip -d /tmp /tmp/jpn-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name, parser):\n",
    "        self.name = name\n",
    "        self.parser = parser\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in self.parser(sentence):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the Japanese language parser\n",
    "\"\"\"\n",
    "\n",
    "import spacy\n",
    "ja = spacy.blank('ja')\n",
    "\n",
    "def parse_japanese(sentence):\n",
    "    return [word for word in ja(sentence)]\n",
    "\n",
    "\"\"\"\n",
    "English can be more complicated than this, \n",
    "but this suffices for this simple model\n",
    "\"\"\"\n",
    "\n",
    "def parse_english(sentence):\n",
    "    return sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_language_pairs(input_file='/tmp/jpn.txt'):\n",
    "    pairs = [] # list of (eng, jpn) pairs\n",
    "    for line in open(input_file, encoding='utf-8').read().splitlines():\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) > 1:\n",
    "            pairs.append((parts[0].strip(), parts[1].strip()))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = parse_language_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48955 samples, 24477 training, 12238 validation, 12240 testing\n"
     ]
    }
   ],
   "source": [
    "# define the training, validation, testing data sets as 50 : 25 : 25\n",
    "sample_size = len(samples)\n",
    "training = samples[0:sample_size // 2]\n",
    "validation = samples[sample_size // 2:(sample_size // 2)+(sample_size // 4)]\n",
    "testing = samples[(sample_size // 2)+(sample_size // 4):]\n",
    "print(\"{} samples, {} training, {} validation, {} testing\"\n",
    "      .format(sample_size, len(training), len(validation), len(testing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
